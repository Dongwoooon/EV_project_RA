{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class별 freq 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir(\"E:/patent\")\n",
    "\n",
    "zf_patent1 = zipfile.ZipFile('harvard_vehicle_patent1.zip') \n",
    "csv_patent1 = zf_patent1.open('harvard_vehicle_patent1.csv')\n",
    "csv_patent_reader1 = csv.reader(csv_patent1)\n",
    "\n",
    "header=csv_patent_reader1.next()\n",
    "mainclass_col = []\n",
    "\n",
    "for j in range(62457,63354):\n",
    "    if 'mainclass' in header[j]:   \n",
    "        mainclass_col.append(j)\n",
    "\n",
    "freq = pd.read_csv('veh_class_freq.csv')\n",
    "veh_class = freq['class'].tolist()\n",
    "veh_class = map(int,veh_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counting 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in csv_patent_reader1:\n",
    "    for i in mainclass_col:\n",
    "        if line[i]=='':   \n",
    "            break\n",
    "    \n",
    "        else:\n",
    "            try:            \n",
    "                if int(line[i]) in veh_class:\n",
    "                # 목표를 포착했다 freq를 1 늘리자\n",
    "                \n",
    "                    for j in range(0,len(veh_class)):\n",
    "                        if int(line[i])==freq.at[j,'class']:\n",
    "                            freq.at[j,'freq'] = freq.at[j,'freq']+1\n",
    "                            break\n",
    "                            # 볼일 다 봤으니 탈출\n",
    "                \n",
    "            except ValueError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zf_patent2 = zipfile.ZipFile('harvard_vehicle_patent2.zip') \n",
    "csv_patent2 = zf_patent2.open('harvard_vehicle_patent2.csv')\n",
    "csv_patent_reader2 = csv.reader(csv_patent2)\n",
    "\n",
    "for line in csv_patent_reader2:\n",
    "    for i in mainclass_col:\n",
    "        if line[i]=='':   \n",
    "            break\n",
    "    \n",
    "        else:\n",
    "            try:            \n",
    "                if int(line[i]) in veh_class:\n",
    "                # 목표를 포착했다 freq를 1 늘리자\n",
    "                \n",
    "                    for j in range(0,len(veh_class)):\n",
    "                        if int(line[i])==freq.at[j,'class']:\n",
    "                            freq.at[j,'freq'] = freq.at[j,'freq']+1\n",
    "                            break\n",
    "                            # 볼일 다 봤으니 탈출\n",
    "                \n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "freq.to_csv('veh_class_freq.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignee별 freq 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Where is info about class?\n",
    "어떤 colummn이 assignee 정보를 담고 있는지 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir(\"E:/patent\")\n",
    "\n",
    "zf_patent1 = zipfile.ZipFile('harvard_vehicle_patent1.zip') \n",
    "csv_patent1 = zf_patent1.open('harvard_vehicle_patent1.csv')\n",
    "csv_patent_reader1 = csv.reader(csv_patent1)\n",
    "\n",
    "header=csv_patent_reader1.next()\n",
    "assignee_col = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "row 몇 개 value 보자\n",
    "\n",
    "19495 부터 assignee col 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  630555\n",
      "1 patent_id_0 4489419\n",
      "2 project_id 4489419\n",
      "3 uuid_0 NaN\n",
      "7635 project_id 4489419\n",
      "7636 uuid_0 NaN\n",
      "19492 project_id 4489419\n",
      "19493 uuid_0 630555\n",
      "19494 patent_id_0 4489419\n",
      "19495 assignee_id_0 nan\n",
      "19496 rawlocation_id_0 ||\n",
      "19497 type_0 nan\n",
      "19498 name_first_0 nan\n",
      "19499 name_last_0 nan\n",
      "19500 organization_0 nan\n",
      "19501 residence_0 nan\n",
      "19502 nationality_0 nan\n",
      "19503 sequence_0 0.0\n",
      "19504 uuid_1 DHPU\n",
      "19505 patent_id_1 4489419\n",
      "19506 assignee_id_1 nan\n",
      "19507 rawlocation_id_1 armonk|ny|\n",
      "19508 type_1 1.0\n",
      "19509 name_first_1 nan\n",
      "19510 name_last_1 nan\n",
      "19511 organization_1 nan\n",
      "19512 residence_1 nan\n",
      "19513 nationality_1 nan\n",
      "19514 sequence_1 0.0\n",
      "19844 project_id 4489419\n",
      "19845 uuid_0 1099973\n",
      "19846 patent_id_0 4489419\n",
      "19847 inventor_id_0 3872959-2\n",
      "19848 rawlocation_id_0 lincoln|ma|us\n",
      "19849 name_first_0 AN\n",
      "19850 name_last_0 WANG\n",
      "19851 sequence_0 1\n",
      "20377 project_id 4489419\n",
      "20378 uuid_0 NaN\n",
      "20402 project_id 4489419\n",
      "20403 uuid_0 NaN\n",
      "32093 project_id 4489419\n",
      "32094 uuid_0 3447680\n",
      "32095 patent_id_0 4489419\n",
      "32096 citation_id_0 2764429\n",
      "32097 date_0 0000-00-00\n",
      "32098 name_0 nan\n",
      "32099 kind_0 nan\n",
      "32100 number_0 2764429\n",
      "32101 country_0 nan\n",
      "32102 category_0 nan\n",
      "32103 sequence_0 2\n",
      "32104 uuid_1 3447684\n",
      "32105 patent_id_1 4489419\n",
      "32106 citation_id_1 3851104\n",
      "32107 date_1 0000-00-00\n",
      "32108 name_1 nan\n",
      "32109 kind_1 nan\n",
      "32110 number_1 3851104\n",
      "32111 country_1 nan\n",
      "32112 category_1 nan\n",
      "32113 sequence_1 6\n",
      "32114 uuid_2 3447683\n",
      "32115 patent_id_2 4489419\n",
      "32116 citation_id_2 3699250\n",
      "32117 date_2 0000-00-00\n",
      "32118 name_2 nan\n",
      "32119 kind_2 nan\n",
      "32120 number_2 3699250\n",
      "32121 country_2 nan\n",
      "32122 category_2 nan\n",
      "32123 sequence_2 5\n",
      "32124 uuid_3 3447678\n",
      "32125 patent_id_3 4489419\n",
      "32126 citation_id_3 2394363\n",
      "32127 date_3 0000-00-00\n",
      "32128 name_3 nan\n",
      "32129 kind_3 nan\n",
      "32130 number_3 2394363\n",
      "32131 country_3 nan\n",
      "32132 category_3 nan\n",
      "32133 sequence_3 0\n",
      "32134 uuid_4 3447682\n",
      "32135 patent_id_4 4489419\n",
      "32136 citation_id_4 3218597\n",
      "32137 date_4 0000-00-00\n",
      "32138 name_4 nan\n",
      "32139 kind_4 nan\n",
      "32140 number_4 3218597\n",
      "32141 country_4 nan\n",
      "32142 category_4 nan\n",
      "32143 sequence_4 4\n",
      "32144 uuid_5 3447681\n",
      "32145 patent_id_5 4489419\n",
      "32146 citation_id_5 3194588\n",
      "32147 date_5 0000-00-00\n",
      "32148 name_5 nan\n",
      "32149 kind_5 nan\n",
      "32150 number_5 3194588\n",
      "32151 country_5 nan\n",
      "32152 category_5 nan\n",
      "32153 sequence_5 3\n",
      "32154 uuid_6 3447679\n",
      "32155 patent_id_6 4489419\n",
      "32156 citation_id_6 2427349\n",
      "32157 date_6 0000-00-00\n",
      "32158 name_6 nan\n",
      "32159 kind_6 nan\n",
      "32160 number_6 2427349\n",
      "32161 country_6 nan\n",
      "32162 category_6 nan\n",
      "32163 sequence_6 1\n",
      "62454 project_id 4489419\n",
      "62455 uuid_0 1IS7T\n",
      "62456 patent_id_0 4489419\n",
      "62457 mainclass_id_0 455\n",
      "62458 subclass_id_0 3.01\n",
      "62459 sequence_0 0.0\n",
      "62460 uuid_1 1IS7S\n",
      "62461 patent_id_1 4489419\n",
      "62462 mainclass_id_1 439\n",
      "62463 subclass_id_1 535\n",
      "62464 sequence_1 0.0\n",
      "62465 uuid_2 1IS7R\n",
      "62466 patent_id_2 4489419\n",
      "62467 mainclass_id_2 375\n",
      "62468 subclass_id_2 219\n",
      "62469 sequence_2 0.0\n",
      "62470 uuid_3 1IS7O\n",
      "62471 patent_id_3 4489419\n",
      "62472 mainclass_id_3 174\n",
      "62473 subclass_id_3 66\n",
      "62474 sequence_3 0.0\n",
      "62475 uuid_4 1IS7P\n",
      "62476 patent_id_4 4489419\n",
      "62477 mainclass_id_4 220\n",
      "62478 subclass_id_4 3.3\n",
      "62479 sequence_4 0.0\n",
      "62480 uuid_5 1IS7N\n",
      "62481 patent_id_5 4489419\n",
      "62482 mainclass_id_5 174\n",
      "62483 subclass_id_5 56\n",
      "62484 sequence_5 0.0\n",
      "62485 uuid_6 1IS7M\n",
      "62486 patent_id_6 4489419\n",
      "62487 mainclass_id_6 375\n",
      "62488 subclass_id_6 257\n",
      "62489 sequence_6 1.0\n",
      "62490 uuid_7 1IS7Q\n",
      "62491 patent_id_7 4489419\n",
      "62492 mainclass_id_7 220\n",
      "62493 subclass_id_7 3.9\n",
      "62494 sequence_7 0.0\n"
     ]
    }
   ],
   "source": [
    "row1 = csv_patent_reader1.next()\n",
    "for i in range(0,len(row1)):\n",
    "    if row1[i] != '':\n",
    "        print i, header[i], row1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nan'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row1[19500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19492 project_id 4489414\n",
      "19493 uuid_0 630550\n",
      "19494 patent_id_0 4489414\n",
      "19495 assignee_id_0 c11f9860a12baad6bc5150a4176667e1\n",
      "19496 rawlocation_id_0 ||\n",
      "19497 type_0 nan\n",
      "19498 name_first_0 nan\n",
      "19499 name_last_0 nan\n",
      "19500 organization_0 HAL COMPUTERS LIMITED\n",
      "19501 residence_0 nan\n",
      "19502 nationality_0 nan\n",
      "19503 sequence_0 0.0\n",
      "19504 uuid_1 DHPY\n",
      "19505 patent_id_1 4489414\n",
      "19506 assignee_id_1 c11f9860a12baad6bc5150a4176667e1\n",
      "19507 rawlocation_id_1 dallas|tx|\n",
      "19508 type_1 3.0\n",
      "19509 name_first_1 nan\n",
      "19510 name_last_1 nan\n",
      "19511 organization_1 HAL COMPUTERS LIMITED\n",
      "19512 residence_1 nan\n",
      "19513 nationality_1 nan\n",
      "19514 sequence_1 0.0\n",
      "19844 project_id 4489414\n",
      "19845 uuid_0 1098742\n",
      "19846 patent_id_0 4489414\n",
      "19847 inventor_id_0 4489414-1\n",
      "19848 rawlocation_id_0 weybridge||gb\n",
      "19849 name_first_0 ROBERT H\n",
      "19850 name_last_0 TITHERLEY\n",
      "19851 sequence_0 1\n"
     ]
    }
   ],
   "source": [
    "row2 = csv_patent_reader1.next()\n",
    "for i in range(19492,20000):\n",
    "    if row2[i] != '':\n",
    "        print i, header[i], row2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19495 assignee_id_0 a0fb2ae9b302a1cd65a882e52e665fdc\n",
      "19496 rawlocation_id_0 kyunggi-do||kr\n",
      "19497 type_0 2.0\n",
      "19498 name_first_0 nan\n",
      "19499 name_last_0 nan\n",
      "19500 organization_0 MAXTOR CORPORATION\n",
      "19501 residence_0 nan\n",
      "19502 nationality_0 nan\n",
      "19503 sequence_0 0.0\n",
      "19844 project_id 5491395\n",
      "19845 uuid_0 3131747\n",
      "19846 patent_id_0 5491395\n",
      "19847 inventor_id_0 5491395-4\n",
      "19848 rawlocation_id_0 longmont|co|us\n",
      "19849 name_first_0 JEFF\n",
      "19850 name_last_0 REH\n",
      "19851 sequence_0 3\n",
      "19852 uuid_1 3130214\n",
      "19853 patent_id_1 5491395\n",
      "19854 inventor_id_1 5466999-1\n",
      "19855 rawlocation_id_1 longmont|co|us\n",
      "19856 name_first_1 LARRY\n",
      "19857 name_last_1 HUTSELL\n",
      "19858 sequence_1 1\n",
      "19859 uuid_2 3130213\n",
      "19860 patent_id_2 5491395\n",
      "19861 inventor_id_2 5491395-2\n",
      "19862 rawlocation_id_2 longmont|co|us\n",
      "19863 name_first_2 GLENN\n",
      "19864 name_last_2 ALBERT\n",
      "19865 sequence_2 4\n",
      "19866 uuid_3 3130212\n",
      "19867 patent_id_3 5491395\n",
      "19868 inventor_id_3 5491395-1\n",
      "19869 rawlocation_id_3 longmont|co|us\n",
      "19870 name_first_3 CURT\n",
      "19871 name_last_3 BRUNER\n",
      "19872 sequence_3 2\n"
     ]
    }
   ],
   "source": [
    "row3 = csv_patent_reader1.next()\n",
    "for i in range(19492,20000):\n",
    "    if row3[i] != '':\n",
    "        print i, header[i], row3[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Problems\n",
    "### 1. assignee ID를 알아볼 수 없음\n",
    "organization 사용\n",
    "\n",
    "### 2. assignee ID = organization?  \n",
    "yes\n",
    "\n",
    "### 3. assignee0 = assingee1 & organization0 = organization1?:  \n",
    "mostly, but not necessarily  \n",
    "  \n",
    "### 4. difference between assignee0 & 1  \n",
    "rawlocation, type  \n",
    "rawlocation : 중복 시 \"\" or 잘못된 정보(대부분)  \n",
    "type : 정체 불명, 중복 시 rawlocation=\"\"이면 \"\", rawlocation!=\"\"이면 숫자  \n",
    "=> raw data 문제!! 일단 넘긴다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prob 2\n",
    "ass_list=[]\n",
    "org_list=[]\n",
    "for i in range(0,200000):\n",
    "    line=csv_patent_reader1.next()\n",
    "    ass_list.append(line[19495])\n",
    "    org_list.append(line[19500])\n",
    "\n",
    "df=pd.DataFrame({'assignee':ass_list, 'organization':org_list})\n",
    "df=df.drop_duplicates()\n",
    "dups=df.duplicated(subset='organization')\n",
    "sum(dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35f85d6346a2374a68ece5a6286551ab /  / VARIABLE SPEECH CONTROL COMPANY (\"VSC\") / \n",
      "dfb1948da91c1cb278590cec9215e2ad /  / SOCIETE NATIONALE D'ETUDE ET DE CONSTRUCTION DE MOTEURS D'AVIATION \"S.N.E.C.M.A. / \n",
      "998 998 998\n"
     ]
    }
   ],
   "source": [
    "# prob 3\n",
    "\n",
    "check_ass=0\n",
    "check_org=0\n",
    "check_same=0\n",
    "for i in range(0,1000):\n",
    "    line=csv_patent_reader1.next()\n",
    "    if line[19495]==line[19506]:\n",
    "        check_ass=check_ass+1\n",
    "    if line[19500]==line[19511]:\n",
    "        check_org=check_org+1\n",
    "    if line[19495]==line[19506] and line[19500]==line[19511]:\n",
    "        check_same=check_same+1\n",
    "    if line[19495]!=line[19506] and line[19500]!=line[19511]:\n",
    "        print line[19495]+' / '+line[19506]+' / '+line[19500]+' / '+line[19511]\n",
    "\n",
    "print check_ass, check_org, check_same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. location 무시하고 assignee list 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic settings\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir(\"E:/patent\")\n",
    "\n",
    "zf_patent1 = zipfile.ZipFile('harvard_vehicle_patent1.zip') \n",
    "csv_patent1 = zf_patent1.open('harvard_vehicle_patent1.csv')\n",
    "csv_patent_reader1 = csv.reader(csv_patent1)\n",
    "header=csv_patent_reader1.next()\n",
    "\n",
    "zf_patent2 = zipfile.ZipFile('harvard_vehicle_patent2.zip') \n",
    "csv_patent2 = zf_patent2.open('harvard_vehicle_patent2.csv')\n",
    "csv_patent_reader2 = csv.reader(csv_patent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select the assignee col\n",
    "assignee_col = []\n",
    "for i in range(0,len(header)):\n",
    "    if 'organization' in header[i]:   \n",
    "        assignee_col.append(i)\n",
    "        \n",
    "del assignee_col[-3:]    #delete lawyer org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#return assignees\n",
    "assignee = []\n",
    "p_id = []\n",
    "for line in csv_patent_reader1:\n",
    "    for i in assignee_col:\n",
    "        if line[i]=='':\n",
    "            break\n",
    "        \n",
    "        elif line[i]=='nan':\n",
    "            assignee.append('private')\n",
    "            p_id.append(line[0])\n",
    "            \n",
    "        else:\n",
    "            assignee.append(line[i])\n",
    "            p_id.append(line[0])\n",
    "            \n",
    "for line in csv_patent_reader2:\n",
    "    for i in assignee_col:\n",
    "        if line[i]=='':\n",
    "            break\n",
    "        \n",
    "        elif line[i]=='nan':\n",
    "            assignee.append('private')\n",
    "            p_id.append(line[0])\n",
    "            \n",
    "        else:\n",
    "            assignee.append(line[i])\n",
    "            p_id.append(line[0])\n",
    "            \n",
    "df = pd.DataFrame({'patent_id':p_id,'assignee':assignee})\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('veh_pid_assignee.csv',index=False)\n",
    "\n",
    "freq=df.groupby(['assignee']).size().reset_index().rename(columns={'0':'count'})\n",
    "freq.columns = ['assignee','freq']\n",
    "freq.to_csv('veh_assignee_freq.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assignee 이름 정리해서 다시 제작\n",
    "### 필요한 이유  \n",
    "assignee - company, company name 기준으로 matching만 완료  \n",
    "company name이 없는 assignee = 투자 받지 않은 assignee는? : 엉망진창  \n",
    "따라서 나중에 patent 단위로 control group을 보기 위해서 patent assignee의 이름을 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir(\"E:/patent\")\n",
    "df=pd.read_csv('veh_pid_assignee.csv')\n",
    "df['new_assignee']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nameprocessing(s):\n",
    "    s = str(s)\n",
    "    \n",
    "    s = s.replace(\".\",\"\")\n",
    "    s = s.replace(\",\",\"\")    \n",
    "    s = s.replace(\";\",\"\")\n",
    "    s = ''.join(s.split()).lower()\n",
    "    \n",
    "    s = s.replace(\"incorporated\",\"inc\")\n",
    "    s = s.replace(\"limited\",\"ltd\")\n",
    "    s = s.replace(\"gmbh\",\"\")\n",
    "    \n",
    "    rm=['inc','ltd','llc','pte']\n",
    "    for i in range(0,len(s)):\n",
    "        if s[-3:] in rm:\n",
    "            s=s[:-3]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-f2e0fe9737fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m520890\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnameprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'veh_pid_assignee.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'new_assignee'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\DW\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[1;31m# scalar callable may return tuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0,len(df.index)):\n",
    "    df.iloc[i,2]=nameprocessing(df.iloc[i,0])\n",
    "    \n",
    "df.to_csv('veh_pid_assignee.csv',index=False)\n",
    "freq=df.groupby(['new_assignee']).size().reset_index().rename(columns={'0':'count'})\n",
    "freq.columns = ['new_assignee','freq']\n",
    "freq.to_csv('veh_new_assignee_freq.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "너무 오래 걸려서 interrupt, checkpoint 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bosecorporation 01234567891011121314151617181920212223242526272829125121712512181251219125122012512211251222125122312512241251225125122612512271251228125122912512301251231125123212512331251234125123512512361251237125123812512391251240125124112512421251243125124412512451251246name:new_assigneedtype:object\n"
     ]
    }
   ],
   "source": [
    "print df.iloc[1151222,2], df.iloc[1151223,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래도 거의 다 했네... checkpoint = 1151222까지 완료  \n",
    "저장해놓고 다음에 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('veh_pid_assignee.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1151222,len(df.index)):\n",
    "    df.iloc[i,2]=nameprocessing(df.iloc[i,0])\n",
    "    \n",
    "df.to_csv('veh_pid_assignee.csv',index=False)\n",
    "freq=df.groupby(['new_assignee']).size().reset_index().rename(columns={'0':'count'})\n",
    "freq.columns = ['new_assignee','freq']\n",
    "freq.to_csv('veh_new_assignee_freq.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firm 별 투자 Freq 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. vehicle patent에 해당하는 row 찾기  \n",
    "우리 scope대로 vehicle 관련 company에 투자한 정보만 찾아야지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir(\"E:/patent\")\n",
    "zf_patent1 = zipfile.ZipFile('all_patent/harvard_dataset_final_merged_output_1.zip') \n",
    "csv_patent1 = zf_patent1.open('harvard_dataset_final_merged_output_1.csv')\n",
    "csv_patent_reader1 = csv.reader(csv_patent1)\n",
    "\n",
    "zf_patent2 = zipfile.ZipFile('all_patent/harvard_dataset_final_merged_output_2.zip')\n",
    "csv_patent2 = zf_patent2.open('harvard_dataset_final_merged_output_2.csv')\n",
    "csv_patent_reader2 = csv.reader(csv_patent2)\n",
    "\n",
    "header = csv_patent_reader1.next()\n",
    "csv_patent_reader2.next()\n",
    "mainclass_col = []\n",
    "for j in range(62457,63354):\n",
    "    if 'mainclass' in header[j]:   \n",
    "        mainclass_col.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classinfo = pd.read_csv('veh_class.csv')\n",
    "veh_class = classinfo['class'].tolist()\n",
    "veh_class = map(int,veh_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "row = []\n",
    "for line in csv_patent_reader1:\n",
    "    for i in mainclass_col:\n",
    "        if line[i]=='':\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            try:            \n",
    "                if int(line[i]) in veh_class:\n",
    "                    row.append(n)\n",
    "                    break\n",
    "                \n",
    "            except ValueError:\n",
    "                pass    \n",
    "    n = n+1\n",
    "    \n",
    "for line in csv_patent_reader2:\n",
    "    for i in mainclass_col:\n",
    "        if line[i]=='':\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            try:            \n",
    "                if int(line[i]) in veh_class:\n",
    "                    row.append(n)\n",
    "                    break\n",
    "                \n",
    "            except ValueError:\n",
    "                pass    \n",
    "    n = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows=zip(row)\n",
    "with open('veh_row.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for val in rows:\n",
    "        writer.writerow(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1439448"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. row에 맞는 투자 정보 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic settings\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.chdir(\"E:/patent\")\n",
    "\n",
    "zf_patent1 = zipfile.ZipFile('all_patent/thomson_harvard_matched.zip') \n",
    "csv_patent1 = zf_patent1.open('thomson_harvard_matched.csv')\n",
    "csv_patent_reader1 = csv.reader(csv_patent1)\n",
    "header = csv_patent_reader1.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firm_col = []\n",
    "for i in range(0,len(header)):\n",
    "    if 'Firm Name' in header[i]:   \n",
    "        firm_col.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "row = pd.read_csv('veh_row.csv')\n",
    "veh_row = row.iloc[:,0].tolist()\n",
    "veh_row = map(int,veh_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firm = []\n",
    "assignee = []\n",
    "amt = []\n",
    "date = []\n",
    "n=0\n",
    "\n",
    "for line in csv_patent_reader1:\n",
    "    if n in veh_row:        \n",
    "        for i in firm_col:\n",
    "            if line[i]=='':\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                firm.append(line[i])\n",
    "                assignee.append(line[i-24])\n",
    "                amt.append(line[i+15])\n",
    "                date.append(line[i+33])\n",
    "        del veh_row[0]\n",
    "        if len(row) == 0:\n",
    "            break\n",
    "        else:\n",
    "            n=n+1\n",
    "    else:\n",
    "        n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'firm':firm,'assignee':assignee,'amount':amt,'date':date})\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('veh_pid_assignee.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
