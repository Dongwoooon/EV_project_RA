{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 A/S\n",
    "\n",
    "### 기본 포맷\n",
    "- patent id, cited id, year, citing firm's info, cited firm's info\n",
    "- year: 1988 ~ 2013\n",
    "- firm info: name, location, financials, (investment)\n",
    "\n",
    "### step\n",
    "1. citation + year -> 이 때, row 수 보고 2개(or 3개)로 쪼갬 => 3개가 낫겠다\n",
    "2. firm info\n",
    "    - name: __1) gvkey-based matching 2) name-processing matching__   \n",
    "    fung data, rule-based processing 활용, compustat과 matching (raw_assignee -> assignee -> new_assignee <-> conm (gvkey))  \n",
    "    gkvey 없었던 애들은 matching을 통해 gvkey 획득  \n",
    "    __=> 결론적으론 gvkey 사용__\n",
    "    - 국가: compustat\n",
    "    - state: 모르겠음\n",
    "    - financial: compustat 환율 이슈 -> 옛날 코드 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. citation + year\n",
    "- compustat 때문에 1988 ~ 2013 가능\n",
    "- 크기 보고 handle이 어려우면 8090 vs 0010 으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "os.chdir('E:/patent/as')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit = pd.read_csv('veh_citation_network.csv')\n",
    "date = pd.read_csv('veh_pid_date_deg.csv')\n",
    "\n",
    "date = date.loc[date['year']>1987,['patent_id','year']]\n",
    "cit = cit.loc[cit['patent_id']>4757709,:]\n",
    "\n",
    "cit = cit.merge(date,how='left',on='patent_id')\n",
    "cit.dropna(how='any',inplace=True)\n",
    "cit.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit0 = cit.loc[cit['year']<2000,:]\n",
    "cit1 = cit.loc[(cit['year']>1999) & (cit['year']<2006),:]\n",
    "cit2 = cit.loc[cit['year']>2005,:]\n",
    "len(cit0), len(cit1), len(cit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cit0.to_csv('cit_year_8090.csv',index=False)\n",
    "cit1.to_csv('cit_year_0005.csv',index=False)\n",
    "cit2.to_csv('cit_year_0613.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. firm info - name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- raw_assingee 붙이기\n",
    "- private 제거하기\n",
    "- raw_assignee -> assignee, dropna\n",
    "- assingee -> gvkey\n",
    "- assingee -> new_assignee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit0 = pd.read_csv('cit_year_8090.csv')\n",
    "cit1 = pd.read_csv('cit_year_0005.csv')\n",
    "cit2 = pd.read_csv('cit_year_0613.csv')\n",
    "\n",
    "raw = pd.read_csv('pid_assignee.csv')\n",
    "raw = raw.loc[:,['patent_id','assignee']]\n",
    "raw.rename(columns={\"assignee\": \"raw_assignee\"},inplace=True)\n",
    "\n",
    "ass = pd.read_csv('assignee_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_x(df):\n",
    "    df = df.merge(raw,how='left',on='patent_id')\n",
    "    df = df.loc[df['raw_assignee']!='private',:]\n",
    "    df = df.merge(ass,how='left',on='raw_assignee')\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    del df['raw_assignee']\n",
    "    \n",
    "    return df\n",
    "\n",
    "cit0 = get_names_x(cit0)\n",
    "cit1 = get_names_x(cit1)\n",
    "cit2 = get_names_x(cit2)\n",
    "\n",
    "list(cit0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.rename(columns={\"patent_id\": \"cited_id\"},inplace=True)\n",
    "\n",
    "def get_names_y(df):    \n",
    "    df = df.merge(raw,how='left',on='cited_id')\n",
    "    df = df.loc[df['raw_assignee']!='private',:]\n",
    "    df = df.merge(ass,how='left',on='raw_assignee',suffixes = ('','_cited'))\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    del df['raw_assignee']\n",
    "    \n",
    "    return df\n",
    "\n",
    "cit0 = get_names_y(cit0)\n",
    "cit1 = get_names_y(cit1)\n",
    "cit2 = get_names_y(cit2)\n",
    "\n",
    "list(cit0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cit = [cit0,cit1,cit2]\n",
    "\n",
    "i=0\n",
    "for df in cit: \n",
    "    df.to_csv('cit_name_'+str(i)+'.csv',index=False)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__gvkey matching__\n",
    "- 양쪽 다 gvkey 있는 애들만 따로 추출 (나중에 쉽게 matching 하것지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cit0 = pd.read_csv('cit_name_0.csv')\n",
    "cit1 = pd.read_csv('cit_name_1.csv')\n",
    "cit2 = pd.read_csv('cit_name_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cited_id',\n",
       " 'patent_id',\n",
       " 'year',\n",
       " 'assignee',\n",
       " 'assignee_cited',\n",
       " 'gvkey',\n",
       " 'gvkey_cited']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv = pd.read_csv('assignee_gvkey.csv')\n",
    "\n",
    "cit0 = cit0.merge(gv,how='left',on='assignee')\n",
    "cit1 = cit1.merge(gv,how='left',on='assignee')\n",
    "cit2 = cit2.merge(gv,how='left',on='assignee')\n",
    "\n",
    "gv.rename(columns={\"assignee\": \"assignee_cited\"},inplace=True)\n",
    "\n",
    "cit0 = cit0.merge(gv,how='left',on='assignee_cited',suffixes = ('','_cited'))\n",
    "cit1 = cit1.merge(gv,how='left',on='assignee_cited',suffixes = ('','_cited'))\n",
    "cit2 = cit2.merge(gv,how='left',on='assignee_cited',suffixes = ('','_cited'))\n",
    "\n",
    "list(cit0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cit = [cit0,cit1,cit2]\n",
    "\n",
    "i=0\n",
    "for df in cit: \n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df.to_csv('cit_gv'+str(i)+'.csv',index=False)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__nameprocessing__\n",
    "- 한 쪽이라도 gvkey 없는 애들 대상\n",
    "- pypy 사용, nameprocessing\n",
    "- compustat conm에도 nameprocessing\n",
    "- matching, gvkey로 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for df in cit:\n",
    "    n = df.loc[(pd.isnull(df['gvkey'])) | (pd.isnull(df['gvkey_cited'])),:]\n",
    "    n.to_csv('cit_np_temp'+str(i)+'.csv',index=False)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nameprocessing(s):\n",
    "    s = s.lower()\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"&\",'and')\n",
    "\n",
    "    rm = ['.',',',';',\"'\",'kabushiki kaisha','kabushikikaisha','limited','company','corporation','incorporated']\n",
    "\n",
    "    for i in rm:\n",
    "        s = s.replace(i,\"\")\n",
    "\n",
    "    sp=s.split()\n",
    "    sp.reverse()\n",
    "\n",
    "    abb=['inc','ltd','llc','pte','plc','kft','co','gmbh','corp','ag','bv','kg']\n",
    "\n",
    "    for i in range(0,len(sp)):\n",
    "        if sp[i] in abb:\n",
    "            sp[i]=''\n",
    "    \n",
    "    sp.reverse()\n",
    "    return ''.join(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### pypy \n",
    "for i in range(0,3):\n",
    "    fr = 'cit_np_temp'+str(i)+'.csv'\n",
    "    fw = 'cit_np'+str(i)+'.csv'\n",
    "    with open(fr,'rb') as r, open(fw,'wb') as w:\n",
    "        reader = csv.reader(r)\n",
    "        header = reader.next()\n",
    "        header = header + ['new_assignee','new_assignee_cited']\n",
    "        \n",
    "        writer = csv.writer(w)\n",
    "        \n",
    "        writer.writerow(header)\n",
    "        \n",
    "        for line in reader:\n",
    "            new_a = nameprocessing(line[3])\n",
    "            new_a_c = nameprocessing(line[4])\n",
    "            \n",
    "            line += [new_a,new_a_c]\n",
    "            \n",
    "            writer.writerow(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = pd.read_csv('compustat_gvkey.csv')\n",
    "com['new_assignee'] = com['conm'].apply(nameprocessing)\n",
    "\n",
    "com.to_csv('compustat_gvkey.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gvkey 붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all',subset=['gvkey','gvkey_com'],inplace=True)\n",
    "df.dropna(how='all',subset=['gvkey_cited','gvkey_cited_com'],inplace=True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if pd.isnull(df.loc[i,'gvkey']):\n",
    "        df.loc[i,'gvkey'] = df.loc[i,'gvkey_com']\n",
    "    \n",
    "    if pd.isnull(df.loc[i,'gvkey_cited']):\n",
    "        df.loc[i,'gvkey_cited'] = df.loc[i,'gvkey_cited_com']\n",
    "        \n",
    "df.drop(['gvkey_com', 'gvkey_cited_com','new_assignee','new_assignee_cited'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    f = 'cit_np'+str(i)+'.csv'\n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    com = pd.read_csv('compustat_gvkey.csv')\n",
    "    del com['conm']\n",
    "\n",
    "    df = df.merge(com,how='left',on='new_assignee',suffixes=('','_com'))\n",
    "    com.rename(columns={\"new_assignee\": \"new_assignee_cited\",'gvkey':'gvkey_cited'},inplace=True)\n",
    "\n",
    "    df = df.merge(com,how='left',on='new_assignee_cited',suffixes=('','_com'))\n",
    "    \n",
    "    df.dropna(how='all',subset=['gvkey','gvkey_com'],inplace=True)\n",
    "    df.dropna(how='all',subset=['gvkey_cited','gvkey_cited_com'],inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    for j in range(0,len(df)):\n",
    "        if pd.isnull(df.loc[j,'gvkey']):\n",
    "            df.loc[j,'gvkey'] = df.loc[j,'gvkey_com']\n",
    "\n",
    "        if pd.isnull(df.loc[j,'gvkey_cited']):\n",
    "            df.loc[j,'gvkey_cited'] = df.loc[j,'gvkey_cited_com']\n",
    "\n",
    "    df.drop(['gvkey_com', 'gvkey_cited_com','new_assignee','new_assignee_cited'], axis=1, inplace=True)\n",
    "    \n",
    "    f = 'cit_np_gv'+str(i)+'.csv'\n",
    "    df.to_csv(f,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    f1 = 'cit_gv'+str(i)+'.csv'\n",
    "    f2 = 'cit_np_gv'+str(i)+'.csv'\n",
    "    \n",
    "    df1 = pd.read_csv(f1)\n",
    "    df2 = pd.read_csv(f2)\n",
    "    \n",
    "    df = pd.concat([df1,df2],ignore_index=True)\n",
    "    \n",
    "    f = 'cit_assignee_'+str(i)+'.csv'\n",
    "    df.to_csv(f,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. firm info  - compustat\n",
    "- 국가\n",
    "- financials \n",
    "- 이 떄, 환율 처리 필요 -> 석사 연구 때 했던 코드 사용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
